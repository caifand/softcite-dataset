---
title: "dataset auditing"
author: Fan Du
Date: 2/25/2020
output: html_notebook
---
Import all the valid codes from RDF data.

```{r}
library(data.world)
library(tidyverse)

prefixes <- "
PREFIX bioj: <http://james.howison.name/ontologies/bio-journal-sample#>
PREFIX bioj-cited: <http://james.howison.name/ontologies/bio-journal-sample-citation#>
PREFIX ca: <http://floss.syr.edu/ontologies/2008/4/contentAnalysis.owl#>
PREFIX citec: <http://james.howison.name/ontologies/software-citation-coding#>
PREFIX dc: <http://dublincore.org/documents/2012/06/14/dcmi-terms/>
PREFIX doap: <http://usefulinc.com/ns/doap#>
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX vivo: <http://vivoweb.org/ontology/core#>
PREFIX xml: <http://www.w3.org/XML/1998/namespace>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
"

softcite_ds = "https://data.world/jameshowison/software-citations/"

valid_codes = c("has_supplement",
"has_in_text_mention",
"coded_no_in_text_mentions",
"memo",
"full_quote",
"on_pdf_page",
"spans_pages",
"mention_type",
"software_was_used",
"software_name",
"version_number",
"version_date",
"url",
"creator",
"has_reference",
"reference_type")

```
Run dwapi::configure()

Get positive selections in the PMC article set.

```{r}
positive_query <- data.world::qry_sparql(paste(prefixes,
      "SELECT ?article ?coder ?selection ?full_quote ?on_pdf_page ?spans_pages
WHERE {
    ?article citec:has_in_text_mention ?selection .
    ?selection ca:isTargetOf
        [ rdf:type ca:CodeApplication ;
          ca:hasCoder ?coder ;
          ca:appliesCode [ rdf:type citec:mention_type ]
        ] .
    ?selection citec:full_quote ?full_quote ;
               citec:on_pdf_page ?on_pdf_page ;
               citec:spans_pages ?spans_pages
    }"
))

pmc_selections <- data.world::query(positive_query, softcite_ds) %>%
  as_tibble() %>% 
  mutate_at(vars(article, selection),
            list(~ str_extract(.,"[#/]([^#/]+)$"))) %>%
  mutate_at(vars(article, selection), list(~ str_sub(.,2))) %>% 
  filter(str_detect(article, "PMC"))
# 5,782 (distinct) quotes from 1,354 PMC articles with positive coding results

pmc_selections %>% group_by(article) %>% 
  summarise(n_coder = n_distinct(coder)) %>% 
  group_by(n_coder) %>% tally()
# among all the positively coded articles, 1,133 single coded. 221 multiply coded.
```

Get PMC articles coded as negative.

```{r}
no_selection_query <- data.world::qry_sparql(paste(prefixes,
      "SELECT ?article ?coder
       WHERE { ?article ca:isTargetOf
               [ rdf:type ca:CodeApplication ;
                 ca:hasCoder ?coder ;
                 ca:appliesCode [ rdf:type citec:coded_no_in_text_mentions ;
                                  citec:isPresent true ]
               ]
    }"
))  

no_selection_articles <- data.world::query(no_selection_query,
                                           dataset = softcite_ds) %>%
  mutate(article = str_extract(article, "[#/]([^#/]+)$"),
         article = str_sub(article,2)) %>%
  collect() %>% 
  filter(str_detect(article, "PMC"))
# 1,197 PMC articles coded as no selection

no_selection_articles %>% group_by(article) %>% 
  summarise(n_coder = n_distinct(coder)) %>% 
  group_by(n_coder) %>% tally()
# 1,031 articles single coded. 166 multiply coded.
```

In total, 2,551 PMC articles coded. 

Normalize text by removing whitespaces, lowering cases, and removing all the quoted url.

```{r}
norm_text <- function(text_to_norm){
  text_to_norm %>%
    str_replace_all("[\\r\\n\\s]" , "") %>% # removing white spaces & line breaks & carriage returns
    str_replace_all("\\(http.*?\\)" , "") %>%
    str_to_lower()
}

test_txt = "The cat sat ON the (http://REMOVE_ME)"
norm_text(test_txt)
```

Tranform PMC XML articles to single strings.

```{r}
library(xml2)
library(glue)

path <- here::here("../softcite-pdf-files/docs/pdf-files/pmc_oa_files/")

test_articles <- tribble(
  ~pmcid,
  "PMC5381613",
  "PMC5421183"
)

articles <- positive_results %>% select(article) %>% distinct()

articles <- articles %>%
  mutate(xml_path = glue_data(., "{path}{article}.xml"),
         article_as_xml = map(xml_path, read_xml),
         pdf_as_string  = map_chr(article_as_xml, xml_text),
         pdf_as_string  = norm_text(pdf_as_string))

```

Align selection with article.

```{r}
library(Biostrings)
library(clipr)

# normalize full_quote
positive_results <- positive_results %>%
  mutate(norm_full_quote = norm_text(full_quote))

# align every selection with the source article
match_in_article <- function(df) {
  art <- df[[1, "article"]] # grouping variable
  pdf_as_string = (articles %>% filter(article == art))$pdf_as_string[[1]]
    df %>% group_by(selection) %>% do(match_selection(., BString(pdf_as_string)))
}


match_selection <- function(df, pdf_as_xstring) {
  norm_full_quote <- df[[1, "norm_full_quote"]]
  # Attempt exact match (without indels) first
  results <- matchPattern(norm_full_quote, pdf_as_xstring)
  if (length(results) == 0) {
      mismatch_allow <- floor(str_length(norm_full_quote) / 10)
      # mismatch_allow <- 10 I tried lots of different values here
      results <- matchPattern(norm_full_quote, pdf_as_xstring,
                          with.indels = T, max.mismatch = mismatch_allow)
  }

  if (length(results) == 0) {
    # warning(paste0("Not found: ", df[[1, "selection"]], "\n"))
    df %>% mutate(found = F, num_found = 0, start_val = NA, end_val = NA)
  } else {
    df %>% mutate(found    = T,
                 num_found = length(results),
                 start_val = list(start(results)),
                 end_val = list(end(results)))
  }
}

(found <- positive_results %>%
  group_by(article) %>%
  do(match_in_article(.)) %>% # adds the num_found, start_val, end_val
  # avoid dealing with ambiguous selections
  # (those found more than once in the one article)
  filter(num_found == 1) %>%
  unnest(cols = c(start_val,end_val)) %>% # unlists the start_val and end_val columns
  ungroup() %>%
  select(-norm_full_quote, -num_found, -found, -spans_pages) %>%
  collect())
# 5,644 selections aligned
```

find agreements and disagreements between selections by different coders.

```{r}
# identify agreed selections by finding overlaps
(matching <- found %>%
  # dots below mean "data frame as passed in" it's a self join.
  inner_join(x = ., y = ., by = "article") %>%
  # can't match own selections
  filter(coder.x != coder.y) %>%
  # overlap definition
  # from http://wiki.c2.com/?TestIfDateRangesOverlap
  # ( start1 <= end2 and start2 <= end1 )
  filter(start_val.x <= end_val.y,
          start_val.y <= end_val.x) %>%
  # used as a check
  # select(full_quote.x, full_quote.y) %>%
  # unite(matched_selections, selection.x, selection.y, sep="---") %>%
  # mutate(matched_selections = ( matched_selections %>%
  #                                str_split("---") %>%
  #                                str_sort() %>%
  #                                str_join() ) ) %>%  
  select(selection = selection.x,
         matching_selection = selection.y) %>%
  collect())
# 2,838 overlapped selection pairs

# left join back to found to leave NAs for those that didn't match  
(found_with_matches <- found %>%
  left_join(matching, by = "selection") %>%
  mutate(matched = if_else(is.na(matching_selection), "unmatched", "matched")) %>%
  collect()) 
# each selection with all its matched selections

no_selection_results <- no_selection_results %>% 
  mutate(matched = 0,
         unmatched = 0)
  
(match_counts <- found_with_matches %>%
  group_by(article, coder, matched) %>%
  summarize(sel_count  = n_distinct(selection)) %>%
  # obtain: article, coder, matched, unmatched
  spread(matched, sel_count, fill=0) %>% # 1,576 rows
  # add: zero counts for article/coder where no selections made.
  ungroup() %>% bind_rows(no_selection_results) %>% # 1,363 rows
  collect())
# counts of matched/unmatched selections by coder each article

match_counts %>%
  summarize(article_count = n_distinct(article))
# 2,506 coded articles with successfully aligned selections

match_counts %>%
  group_by(article) %>%
  summarize(num_coder = n_distinct(coder)) %>%
  group_by(num_coder) %>%
  tally()
# over 2,506 articles, 2,086 single coded, 420 multiply coded.
# This result is more accurate since it counts the possibility of one positively coded article was treated negatively by another coder.
```

Computing selection agreement.

```{r}
# define article-level percentage agreement
my_summarize <- function(df) {
  matched = df[[1, "matched"]]
  coder_a_name = df[[1, "coder"]]
  coder_a_only = df[[1, "unmatched"]]

  if (nrow(df) > 1) {
    coder_b_name = df[[2, "coder"]]
    coder_b_only = df[[2, "unmatched"]]
    total_selections <- matched + coder_a_only + coder_b_only
    if (total_selections == 0) {
      percent_agree <- NA
    } else {
      percent_agree <- matched / total_selections %>% round(2)
    }
  } else {
    coder_b_name <-  NA
    coder_b_only <-  NA
    total_selections <- matched + coder_a_only
    percent_agree <- NA
  }

  tibble(percent_agree = percent_agree,
         matched = matched,
         coder_a_only = coder_a_only,
         coder_a_name = coder_a_name,
         coder_b_only = coder_b_only,
         coder_b_name = coder_b_name)
}

# Now obtain:
# article, matched, coder_a_only, coder_a_name, coder_b_only, coder_b_name
simple_agree_counts_by_article <- match_counts %>%
  group_by(article) %>%
  do(my_summarize(.)) %>% # runs my_summarize for each grouped chunk of the df
  arrange(percent_agree)
# get percentage agreement per article

simple_agree_counts_by_article <- simple_agree_counts_by_article %>%
  ungroup() %>% 
  mutate(valid_agreement = case_when(
    is.na(percent_agree) ~ FALSE,
    TRUE ~ TRUE
  )
  )

simple_agree_counts_by_article %>%
  group_by(valid_agreement) %>%
  tally()
# 258 PMC articles with valid agreement

simple_agree_counts_by_article %>% 
  filter(valid_agreement == T) %>% 
  summarize(mean_percent_agree = mean(percent_agree))

# how many with 100%?
simple_agree_counts_by_article %>%
  filter(!is.na(percent_agree)) %>%
  mutate(ranking_group = case_when(
    percent_agree == 0 ~ "none",
    percent_agree <= 0.5 ~ "under_half",
    percent_agree < 1 ~ "over_half",
    percent_agree == 1 ~ "all"
  )) %>%
  group_by(ranking_group) %>%
  summarize(article_count = n(),
            group_mean = mean(percent_agree))

simple_agree_counts_by_article %>%
  filter(valid_agreement == T) %>% # single coder articles or none found.
  ggplot() +
  geom_histogram(aes(x=percent_agree), bins=5)

simple_agree_counts_by_article %>%
  summarize(overall_mean_agreement = mean(percent_agree, na.rm = T))

pmc_articles_valid_agreement <- simple_agree_counts_by_article %>% 
  filter(valid_agreement == T) %>% 
  distinct(article)
```


March 4, 2020. Wed

Another way around. Same as we constructed the csv dataset.

```{r}
library(tidyverse)
library(SPARQL)
library(here)
library(data.world)

softcite_ds = "https://data.world/jameshowison/software-citations/"
```

```{r}
prefixes <- "PREFIX bioj: <http://james.howison.name/ontologies/bio-journal-sample#>
PREFIX bioj-cited: <http://james.howison.name/ontologies/bio-journal-sample-citation#>
PREFIX ca: <http://floss.syr.edu/ontologies/2008/4/contentAnalysis.owl#>
PREFIX citec: <http://james.howison.name/ontologies/software-citation-coding#> 
PREFIX dc: <http://dublincore.org/documents/2012/06/14/dcmi-terms/>
PREFIX doap: <http://usefulinc.com/ns/doap#>
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX vivo: <http://vivoweb.org/ontology/core#>
PREFIX xml: <http://www.w3.org/XML/1998/namespace>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
"
```

Get article-level article, article_set, coder, no_selections_found

```{r}
articles_string <- "SELECT DISTINCT ?article ?article_set ?coder ?no_selections_found
WHERE {
  ?article rdf:type ?article_set;
           ca:isTargetOf
        [ rdf:type ca:CodeApplication ;
          ca:hasCoder ?coder ;
          ca:appliesCode [ rdf:type citec:coded_no_in_text_mentions ;
                           citec:isPresent ?no_selections_found; 
                         ] ;
        ] ;
  FILTER(?article_set != bioj:article)
}
"

articles <- data.world::qry_sparql(paste0(prefixes, articles_string)) %>%
  data.world::query(softcite_ds) %>% 
  as_tibble() %>% 
  mutate_at(vars(article, article_set),
            list(~ str_extract(.,"[#/]([^#/]+)$"))) %>%
  mutate_at(vars(article, article_set), list(~ str_sub(.,2))) 
```

article-level stats

```{r}
articles %>% group_by(article_set) %>% 
  summarise(set_n = n_distinct(article)) %>% 
  summarise(sum(set_n))
# 2 training articles. 2,521 PMC articles, 2,450 econ articles, 1 bio article.
# 4,974 articles coded in total

articles %>% group_by(no_selections_found) %>% 
  tally()
# 1,832 articles coded as no mention; 3,731 coded with selections

articles %>% select(article_set) %>% distinct()
articles %>% filter(article_set == "bio_article")
```

selection, coder, article, quote, tei_quote, page, mention_type, certainty, memo

```{r}
in_text_mention_query <- "SELECT DISTINCT ?selection ?coder ?article ?quote ?tei_quote ?page ?mention_type ?certainty ?memo
WHERE {
	?article citec:has_in_text_mention ?selection .
	?selection citec:full_quote ?quote ;
	           citec:on_pdf_page ?page ;
	           ca:isTargetOf [ ca:hasCoder ?coder ;
                             ca:appliesCode [ rdf:type citec:mention_type ;
                                              rdfs:label ?mention_type ;
                                              ca:certainty ?certainty ;
                                              ca:memo ?memo ]
                            ]
  OPTIONAL { ?selection citec:tei_full_quote ?tei_quote }
}
"

in_text_mentions <- data.world::qry_sparql(paste0(prefixes, in_text_mention_query)) %>%
  data.world::query(softcite_ds) %>% 
  as_tibble() %>% 
  mutate_at(vars(article, selection),
            list(~ str_extract(.,"[#/]([^#/]+)$"))) %>%
  mutate_at(vars(article, selection), list(~ str_sub(.,2)))
```

selection statistics

```{r}
# 7,027 in-text selection entries
in_text_mentions %>% filter(!is.na(tei_quote))
# 547 tei_quote

in_text_mentions %>% group_by(mention_type) %>% tally()
# 6,440 annotated software mentions, 597 non-software annotations
# non-software categories: 140 web_platform, 170 other, 128 hardware, 39 database, 110 algorithm (How valid are they? Possible to review again?)

in_text_mentions %>% 
  group_by(article, selection) %>% 
  summarise(coder_n = n_distinct(coder)) %>% 
  arrange(desc(coder_n)) %>% 
  group_by(coder_n) %>% 
  mutate(num_article = n_distinct(article)) %>%
  select(coder_n, num_article) %>%
  distinct() 
  # ggplot() +
  # geom_bar(aes(coder_n)) + xlab("# of coders")

```

Check article-level agreement

```{r}
# look at only positively coded articles
articles %>% filter(no_selections_found == FALSE) %>% 
  group_by(article, article_set) %>% 
  summarise(n_coder = n_distinct(coder)) %>%
  filter(n_coder > 1, article_set %in% c("pmc_article", "econ_article"))
# more than 1 coder agrees on that this article has mentions: 218 PMC articles; 1 training article; 12 econ articles; 1 bio article; 1 training article.

# look at all the coded articles
articles %>% 
  group_by(article, article_set) %>% 
  summarise(n_coder = n_distinct(coder)) %>% 
  filter(article_set == "econ_article") %>% 
  distinct() %>% filter(n_coder > 1)
# 2,450 econ articles; 225 articles have codings; among them 12 are multiply coded
# 153 econ articles are multiply coded (still, only 12 have positive results)

articles %>% filter(article_set == "econ_article") %>% group_by(article) %>% 
  summarise(n_coder = n_distinct(coder)) %>% 
  filter(n_coder > 1)
```